# -*- coding: utf-8 -*-
"""the_Bloke_Wizard.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QC5FSPlsFTvfI9VUah8_Xj_i20R-dLKj
"""

# This line imports AutoTokenizer
from transformers import AutoModelForCausalLM, AutoTokenizer
import numpy as np
import time
import os
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

# checkpoint
checkpoint = "microsoft/DialoGPT-medium"
# download and cache tokenizer
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
# download and cache pre-trained model
model = AutoModelForCausalLM.from_pretrained(checkpoint)


# !pip install optimum

# Build a ChatBot class with all necessary modules to make a complete conversation

class ChatBot():
    # initialize
    def __init__(self):
        # once chat starts, the history will be stored for chat continuity
        self.chat_history_ids = None
        # make input ids global to use them anywhere within the object
        self.bot_input_ids = None
        # a flag to check whether to end the conversation
        self.end_chat = False
        # greet while starting
        # self.welcome()

    # def welcome(self):
    #     print("Initializing ChatBot ...")
    #     # some time to get user ready
    #     time.sleep(2)
    #     print('Type "bye" or "quit" or "exit" to end chat \n')
    #     # give time to read what has been printed
    #     time.sleep(3)
    #     # Greet and introduce
    #     greeting = np.random.choice([
    #         "Welcome, I am ChatBot, here for your kind service",
    #         "Hey, Great day! I am your virtual assistant",
    #         "Hello, it's my pleasure meeting you",
    #         "Hi, I am a ChatBot. Let's chat!"
    #     ])
    #     print("ChatBot >>  " + greeting)

    def user_input(self,userInput):
        # receive input from user
        text = userInput
        # end conversation if user wishes so
        if text.lower().strip() in ['bye', 'quit', 'exit']:
            # turn flag on
            self.end_chat = True
            # a closing comment
            print('ChatBot >>  See you soon! Bye!')
            time.sleep(1)
            print('\nQuitting ChatBot ...')
        else:
            # continue chat, preprocess input text
            # encode the new user input, add the eos_token and return a tensor in Pytorch
            self.new_user_input_ids = tokenizer.encode(text + tokenizer.eos_token,
                                                       return_tensors='pt')

    def bot_response(self):  # Indent this function to make it a method of the ChatBot class
        # Prepare the input sequence for the model
        bot_input_ids = self.bot_input_ids.clone().detach(
        ) if self.bot_input_ids is not None else self.new_user_input_ids
        bot_input_ids = torch.cat(
            [bot_input_ids, self.new_user_input_ids], dim=-1)

        # Generate a response while limiting the total chat history to 1000 tokens
        chat_history_ids = model.generate(
            bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)

        # Decode the response and print it
        response = tokenizer.decode(
            chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)
        # print('ChatBot >>  ' + response)

        # Update bot_input_ids with the latest conversation history
        self.bot_input_ids = chat_history_ids

        return response

    # in case there is no response from model
    def random_response(self):
        i = -1
        response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0],
                                    skip_special_tokens=True)
        # iterate over history backwards to find the last token
        while response == '':
            i = i-1
            response = tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[i]:][0],
                                        skip_special_tokens=True)
        # if it is a question, answer suitably
        if response.strip() == '?':
            reply = np.random.choice(["I don't know",
                                     "I am not sure"])
        # not a question? answer suitably
        else:
            reply = np.random.choice(["Great",
                                      "Fine. What's up?", ])


'''# build a ChatBot object
bot = ChatBot()
# start chatting
while True:
    # receive user input
    bot.user_input()
    # check whether to end chat
    if bot.end_chat:
        break
    # output bot response
    bot.bot_response()'''
